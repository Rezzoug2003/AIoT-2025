{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrlARzyP1yo3",
        "outputId": "5843de12-2d90-40bc-d247-0e7eaac76a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/smoke_detection_iot.csv\", sep=None, engine='python')\n",
        "\n",
        "df = df.dropna(axis=1, how='all')\n",
        "df.columns = df.columns.str.strip().str.replace('\"', '').str.replace('\\ufeff', '')\n",
        "\n",
        "print(\"âœ… Auto-detected columns:\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wF1s3Aj9Ctz",
        "outputId": "89a65f72-cfc8-4970-c667-f3083f1f22dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Auto-detected columns:\n",
            "['Unnamed: 0', 'UTC', 'Temperature[C]', 'Humidity[%]', 'TVOC[ppb]', 'eCO2[ppm]', 'Raw H2', 'Raw Ethanol', 'Pressure[hPa]', 'PM1.0', 'PM2.5', 'NC0.5', 'NC1.0', 'NC2.5', 'CNT', 'Fire Alarm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'Fire Alarm'\n",
        "\n",
        "# Drop rows with missing target values\n",
        "df = df.dropna(subset=[target_col])\n",
        "\n",
        "# Prepare X and y\n",
        "X = df.drop(columns=[target_col], errors='ignore')\n",
        "y = df[target_col]\n",
        "\n",
        "# Drop any remaining NaNs\n",
        "X = X.dropna()\n",
        "y = y.loc[X.index]\n",
        "\n",
        "print(\"âœ… X shape:\", X.shape, \" | y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gua4rIBl6kuT",
        "outputId": "f7f2b323-4ec4-4464-fc3b-0681aad6baa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… X shape: (62630, 16)  | y shape: (62630,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ab1ddf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHQ75Z_s92lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66af66a-caad-4845-8d99-5b68ccaae6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Logistic Regression Accuracy: 0.988\n",
            "ðŸ”¹ Logistic Regression F1 Score: 0.992\n",
            "ðŸ”¹ Training Time: 1.423 seconds\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define pipeline\n",
        "lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train\n",
        "start = time.time()\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "lr_time = time.time() - start\n",
        "\n",
        "# Evaluate\n",
        "y_pred_lr = lr_pipeline.predict(X_test)\n",
        "lr_acc = accuracy_score(y_test, y_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"ðŸ”¹ Logistic Regression Accuracy: {lr_acc:.3f}\")\n",
        "print(f\"ðŸ”¹ Logistic Regression F1 Score: {lr_f1:.3f}\")\n",
        "print(f\"ðŸ”¹ Training Time: {lr_time:.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define pipeline\n",
        "xgb_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # kept for MLOps consistency\n",
        "    ('classifier', XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "start = time.time()\n",
        "xgb_pipeline.fit(X_train, y_train)\n",
        "xgb_time = time.time() - start\n",
        "\n",
        "# Evaluate\n",
        "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
        "xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"ðŸŒ³ XGBoost Accuracy: {xgb_acc:.3f}\")\n",
        "print(f\"ðŸŒ³ XGBoost F1 Score: {xgb_f1:.3f}\")\n",
        "print(f\"ðŸŒ³ Training Time: {xgb_time:.3f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4DOnyRw0IVz",
        "outputId": "ebfdc341-53f3-4f3c-e04f-060c2cc08770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:17:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ³ XGBoost Accuracy: 1.000\n",
            "ðŸŒ³ XGBoost F1 Score: 1.000\n",
            "ðŸŒ³ Training Time: 0.851 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Logistic Regression runtime\n",
        "start_time = time.time()\n",
        "_ = lr_pipeline.predict(X_test)\n",
        "lr_time = time.time() - start_time\n",
        "\n",
        "# XGBoost runtime\n",
        "start_time = time.time()\n",
        "_ = xgb_pipeline.predict(X_test)\n",
        "xgb_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nRuntime (seconds):\")\n",
        "print(f\"LR-Pipeline: {lr_time:.5f}\")\n",
        "print(f\"XGB-Pipeline: {xgb_time:.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXOEN7J90UZO",
        "outputId": "ded15b79-3ad2-457f-abb3-64f9a688d335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Runtime (seconds):\n",
            "LR-Pipeline: 0.00675\n",
            "XGB-Pipeline: 0.02720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DsOrCA90sVQ",
        "outputId": "6d1738f1-e966-4228-a2dc-f03ab4d03844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from memory_profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, os, psutil\n",
        "\n",
        "# Save models\n",
        "joblib.dump(lr_pipeline, \"lr_pipeline.joblib\")\n",
        "joblib.dump(xgb_pipeline, \"xgb_pipeline.joblib\")\n",
        "\n",
        "# Model sizes in KB\n",
        "lr_size = os.path.getsize(\"lr_pipeline.joblib\") / 1024\n",
        "xgb_size = os.path.getsize(\"xgb_pipeline.joblib\") / 1024\n",
        "\n",
        "# Current system memory usage\n",
        "mem_usage = psutil.virtual_memory().percent\n",
        "\n",
        "print(\"\\nðŸ’¾ Resource Summary:\")\n",
        "print(f\"â€¢ Logistic Regression model size: {lr_size:.2f} KB\")\n",
        "print(f\"â€¢ XGBoost model size: {xgb_size:.2f} KB\")\n",
        "print(f\"â€¢ Current system RAM usage: {mem_usage:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0OX1jMG0hS9",
        "outputId": "674f18d8-cb08-4684-b4cb-d55e8c768022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ’¾ Resource Summary:\n",
            "â€¢ Logistic Regression model size: 2.22 KB\n",
            "â€¢ XGBoost model size: 126.30 KB\n",
            "â€¢ Current system RAM usage: 8.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# TP4 - Model Preparation Script\n",
        "# Generates: lr_pipeline.pkl, xgb_pipeline.pkl\n",
        "# ============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "import pickle\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Load and clean dataset\n",
        "# ----------------------------\n",
        "df = pd.read_csv(\"/content/smoke_detection_iot.csv\", sep=None, engine='python')\n",
        "\n",
        "df = df.dropna(axis=1, how='all')\n",
        "df.columns = df.columns.str.strip().str.replace('\"', '').str.replace('\\ufeff', '')\n",
        "\n",
        "print(\"âœ… Auto-detected columns:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# df = pd.read_csv(file_path, sep=\";\", skiprows=1, names=columns)\n",
        "df = df.dropna(axis=1, how=\"all\")  # drop empty columns\n",
        "df = df.dropna()  # drop missing rows\n",
        "\n",
        "# Clean column names\n",
        "df.columns = [c.strip().replace('\"', \"\") for c in df.columns]\n",
        "\n",
        "print(\"âœ… Cleaned columns:\", df.columns.tolist()[:10], \"...\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Select features + target\n",
        "# ----------------------------\n",
        "# Target = Fire Alarm\n",
        "target_col = \"Fire Alarm\"\n",
        "if target_col not in df.columns:\n",
        "    raise ValueError(f\"Column '{target_col}' not found! Check dataset structure.\")\n",
        "\n",
        "# Select numeric sensor features\n",
        "features = [\n",
        "   'Unnamed: 0', 'UTC', 'Temperature[C]', 'Humidity[%]', 'TVOC[ppb]', 'eCO2[ppm]', 'Raw H2', 'Raw Ethanol', 'Pressure[hPa]', 'PM1.0', 'PM2.5', 'NC0.5', 'NC1.0', 'NC2.5', 'CNT'\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df[target_col]\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Train/test split\n",
        "# ----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Logistic Regression Pipeline\n",
        "# ----------------------------\n",
        "lr_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr_pipeline.predict(X_test)\n",
        "print(\"\\nðŸ”¹ Logistic Regression Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
        "\n",
        "# Save model\n",
        "# Create the directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs(\"TP4/models\", exist_ok=True)\n",
        "\n",
        "with open(\"TP4/models/lr_pipeline.pkl\", \"wb\") as f:\n",
        "    pickle.dump(lr_pipeline, f)\n",
        "print(\"âœ… Saved: TP4/models/lr_pipeline.pkl\")\n",
        "\n",
        "# ----------------------------\n",
        "# 5. XGBoost Pipeline\n",
        "# ----------------------------\n",
        "xgb_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),  # for consistency in MLOps\n",
        "    (\"model\", XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=4,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "xgb_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
        "print(\"\\nðŸ”¹ XGBoost Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_xgb))\n",
        "\n",
        "# Save model\n",
        "with open(\"TP4/models/xgb_pipeline.pkl\", \"wb\") as f:\n",
        "    pickle.dump(xgb_pipeline, f)\n",
        "print(\"âœ… Saved: TP4/models/xgb_pipeline.pkl\")\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Optional: Model sizes\n",
        "# ----------------------------\n",
        "import os\n",
        "lr_size = os.path.getsize(\"TP4/models/lr_pipeline.pkl\") / 1024\n",
        "xgb_size = os.path.getsize(\"TP4/models/xgb_pipeline.pkl\") / 1024\n",
        "print(f\"\\nðŸ“¦ Model sizes -> Logistic: {lr_size:.2f} KB | XGBoost: {xgb_size:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U61VBiLkQ34C",
        "outputId": "8cd8816a-354a-4423-ac92-a8b56eb2edba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Auto-detected columns:\n",
            "['Unnamed: 0', 'UTC', 'Temperature[C]', 'Humidity[%]', 'TVOC[ppb]', 'eCO2[ppm]', 'Raw H2', 'Raw Ethanol', 'Pressure[hPa]', 'PM1.0', 'PM2.5', 'NC0.5', 'NC1.0', 'NC2.5', 'CNT', 'Fire Alarm']\n",
            "âœ… Cleaned columns: ['Unnamed: 0', 'UTC', 'Temperature[C]', 'Humidity[%]', 'TVOC[ppb]', 'eCO2[ppm]', 'Raw H2', 'Raw Ethanol', 'Pressure[hPa]', 'PM1.0'] ...\n",
            "\n",
            "ðŸ”¹ Logistic Regression Results:\n",
            "Accuracy: 0.9869072329554527\n",
            "F1 Score: 0.9908256880733946\n",
            "âœ… Saved: TP4/models/lr_pipeline.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:21:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ XGBoost Results:\n",
            "Accuracy: 0.9999201660546064\n",
            "F1 Score: 0.9999441371990392\n",
            "âœ… Saved: TP4/models/xgb_pipeline.pkl\n",
            "\n",
            "ðŸ“¦ Model sizes -> Logistic: 1.77 KB | XGBoost: 114.91 KB\n"
          ]
        }
      ]
    }
  ]
}